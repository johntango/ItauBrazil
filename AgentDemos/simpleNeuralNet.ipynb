{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Net to Solve Ordinary Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Mean Squared Error: 19.314998294504438\n",
      "Epoch 100, Mean Squared Error: 0.009703492304988747\n",
      "Epoch 200, Mean Squared Error: 0.0049290573260395995\n",
      "Epoch 300, Mean Squared Error: 0.002503800215402189\n",
      "Epoch 400, Mean Squared Error: 0.0012718487743142027\n",
      "Epoch 500, Mean Squared Error: 0.0006460576585838984\n",
      "Epoch 600, Mean Squared Error: 0.0003281762003819787\n",
      "Epoch 700, Mean Squared Error: 0.00016670279667176544\n",
      "Epoch 800, Mean Squared Error: 8.467957879286133e-05\n",
      "Epoch 900, Mean Squared Error: 4.30144617108945e-05\n",
      "Trained weights: [[2.00303475]\n",
      " [0.98904358]]\n",
      "Predictions for test data: [[13.00725209]\n",
      " [15.01028685]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate some sample data for training\n",
    "# y = 2x + 1\n",
    "x = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([[3], [5], [7], [9], [11]])\n",
    "\n",
    "# Initialize weights (slope and bias)\n",
    "weights = np.random.rand(2, 1)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Training the neural network\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass (simple linear function)\n",
    "    # Adding a bias term (1) to each input\n",
    "    x_with_bias = np.c_[x, np.ones(x.shape[0])]\n",
    "    predicted_y = np.dot(x_with_bias, weights)\n",
    "    \n",
    "    # Error calculation\n",
    "    error = y - predicted_y\n",
    "    mean_squared_error = np.mean(np.square(error))\n",
    "    \n",
    "    # Backpropagation (Gradient Descent)\n",
    "    gradient = -2 * np.dot(x_with_bias.T, error) / x.shape[0]\n",
    "    weights -= learning_rate * gradient\n",
    "    \n",
    "    # Logging the learning process\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Mean Squared Error: {mean_squared_error}\")\n",
    "\n",
    "# Final weights\n",
    "print(f\"Trained weights: {weights}\")\n",
    "\n",
    "# Test the neural network\n",
    "test_x = np.array([[6], [7]])\n",
    "test_x_with_bias = np.c_[test_x, np.ones(test_x.shape[0])]\n",
    "predicted_test_y = np.dot(test_x_with_bias, weights)\n",
    "\n",
    "print(f\"Predictions for test data: {predicted_test_y}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
